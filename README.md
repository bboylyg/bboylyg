### Hi there, I am Yige Li ğŸ‘‹

I am a research fellow at the School of Computing and Information Systems at [Singapore Management University](https://www.smu.edu.sg/) supervised by Prof. [Jun Sun](https://scholar.google.com/citations?user=DVsEyn0AAAAJ&hl=zh-CN). I also work closely with Prof. [Xingjun Ma](https://scholar.google.com/citations?user=XQViiyYAAAAJ&hl=zh-CN) at Fudan University. I completed my Ph.D. at [Xidian University](https://www.xidian.edu.cn/) under the supervision of Prof. [Xixiang Lyu](https://web.xidian.edu.cn/xxlv/).  
Research publications: [Google Scholar](https://scholar.google.com/citations?user=h0cS2nQAAAAJ&hl=zh-EN)


I pursue research in **Trustworthy AI**, aiming to build secure, robust, and interpretable systems that align with human values and cognition.  
Iâ€™m especially interested in **generative models** and **AI safety**, and I seek simple yet insightful solutions grounded in theory. Guided by the philosophy *"Everything should be made as simple as possible, but not simpler,"* I approach research with both rigor and curiosity.  

Outside of work, I enjoy **rock climbing** ğŸ§— and **swimming** ğŸŠ.


### ğŸ”­ My research mainly focus on:

- Understanding the eï¬€ectiveness of backdoor attacks
- Robust training against backdoor attacks
- Design and implement a general defense framework for backdoor attacks

<!-- ### ğŸ¤” My Internship Experience:

- Beijing Samsung Electronics Research Institute (*2018.06-2018.09*)
  - Review study on model lightweight methods
  - Lightweight face detection based on MtCNN
- Beijing Thunder R&D Center (*2018.03-2018.06*)
  - Large-scale video retrieval based on perceptual hash
  - Web video annotation tool development -->

### ğŸŒ± Publications:  

- **Yige Li**, Xingjun Ma, et al., â€œMulti-Trigger Backdoor Attacks: More Triggers, More Threatsâ€, submitting, 2024. 
- **Yige Li**, Xixiang Lyu, et al., â€œReconstructive Neuron Pruning for Backdoor Defenseâ€, ICML 2023.  
- **Yige Li**, Xixiang Lyu, et al., â€œAnti-Backdoor Learning: Training Clean Models on Poisoned Dataâ€, NeurIPS 2021.
- **Yige Li**, Xixiang Lyu, et al., â€œNeural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networksâ€, ICLR 2021.
<!-- - å¼ ç…œï¼Œå•é”¡é¦™ï¼Œé‚¹å®‡èªï¼Œ **æä¸€æˆˆ**ï¼Œâ€œåŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„æ–‡æœ¬åºåˆ—æ•°æ®é›†è„±æ•â€ï¼Œç½‘ç»œå®‰å…¨å­¦æŠ¥ï¼Œ 2020.
- ç”°å®¶ä¼šï¼Œå•é”¡é¦™ï¼Œé‚¹ä»æœ‹ï¼Œ **æä¸€æˆˆ**ï¼Œâ€œä¸€ç§è”é‚¦å­¦ä¹ ä¸­çš„å…¬å¹³èµ„æºåˆ†é…æ–¹æ¡ˆâ€ï¼Œè®¡ç®—æœºç ”ç©¶ä¸å‘å±•ï¼Œ 2021. -->

### âš¡ Significance of our works:

- **Neural Attention Distillation (NAD)**
  - A simple and universal method against 6 state-of-the-art backdoor attacks via knowledge distillation
  - Only a small amount of clean data is required (5%)
  - Only a few epochs of fine-tuning (2-10 epochs) are required

- **Anti-Backdoor Learning (ABL)**
  - Simple, effective, and universal, can defend against 10 state-of-the-art backdoor attacks
  - 1\% isolation data is required
  - A novel stratrgy benefit companies, research institutes, or government agencies to train backdoor-free machine learning models

### ğŸ“« How to reach me:

- yigeli@smu.edu.sg  
- yglee@stu.xidian.edu.cn  


<!--
**Yige-Li** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
  -->
