### Hi there, I am Yige Li 👋

I am a research fellow at the School of Computing and Information Systems at [Singapore Management University](https://www.smu.edu.sg/) supervised by Prof. [Jun Sun](https://scholar.google.com/citations?user=DVsEyn0AAAAJ&hl=zh-CN). I also work closely with Prof. [Xingjun Ma](https://scholar.google.com/citations?user=XQViiyYAAAAJ&hl=zh-CN) at Fudan University. I completed my Ph.D. at [Xidian University](https://www.xidian.edu.cn/) under the supervision of Prof. [Xixiang Lyu](https://web.xidian.edu.cn/xxlv/).  
Research publications: [Google Scholar](https://scholar.google.com/citations?user=h0cS2nQAAAAJ&hl=zh-EN)


I pursue research in **Trustworthy AI**, aiming to build secure, robust, and interpretable systems that align with human values and cognition.  
I’m especially interested in **generative models** and **AI safety**, and I seek simple yet insightful solutions grounded in theory. Guided by the philosophy *"Everything should be made as simple as possible, but not simpler,"* I approach research with both rigor and curiosity.  

Outside of work, I enjoy **rock climbing** 🧗 and **swimming** 🏊.


### 🔭 My research mainly focus on:

- Understanding the eﬀectiveness of backdoor attacks
- Robust training against backdoor attacks
- Design and implement a general defense framework for backdoor attacks

<!-- ### 🤔 My Internship Experience:

- Beijing Samsung Electronics Research Institute (*2018.06-2018.09*)
  - Review study on model lightweight methods
  - Lightweight face detection based on MtCNN
- Beijing Thunder R&D Center (*2018.03-2018.06*)
  - Large-scale video retrieval based on perceptual hash
  - Web video annotation tool development -->

### 🌱 Publications:  

- **Yige Li**, Xingjun Ma, et al., “Multi-Trigger Backdoor Attacks: More Triggers, More Threats”, submitting, 2024. 
- **Yige Li**, Xixiang Lyu, et al., “Reconstructive Neuron Pruning for Backdoor Defense”, ICML 2023.  
- **Yige Li**, Xixiang Lyu, et al., “Anti-Backdoor Learning: Training Clean Models on Poisoned Data”, NeurIPS 2021.
- **Yige Li**, Xixiang Lyu, et al., “Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks”, ICLR 2021.
<!-- - 张煜，吕锡香，邹宇聪， **李一戈**，“基于生成对抗网络的文本序列数据集脱敏”，网络安全学报， 2020.
- 田家会，吕锡香，邹仁朋， **李一戈**，“一种联邦学习中的公平资源分配方案”，计算机研究与发展， 2021. -->

### ⚡ Significance of our works:

- **Neural Attention Distillation (NAD)**
  - A simple and universal method against 6 state-of-the-art backdoor attacks via knowledge distillation
  - Only a small amount of clean data is required (5%)
  - Only a few epochs of fine-tuning (2-10 epochs) are required

- **Anti-Backdoor Learning (ABL)**
  - Simple, effective, and universal, can defend against 10 state-of-the-art backdoor attacks
  - 1\% isolation data is required
  - A novel stratrgy benefit companies, research institutes, or government agencies to train backdoor-free machine learning models

### 📫 How to reach me:

- yigeli@smu.edu.sg  
- yglee@stu.xidian.edu.cn  


<!--
**Yige-Li** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
  -->
